{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_FaceRecog_GetFaceEmbeddings.ipynb","provenance":[],"authorship_tag":"ABX9TyOtPhPQEXrX9enMqNtlbJMM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Dzqd8hyXHOdv"},"source":["pip install dlib"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yv3sAS1oJCej","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620888382490,"user_tz":-330,"elapsed":35874,"user":{"displayName":"Unnikrishnan C S","photoUrl":"","userId":"18301413610349739582"}},"outputId":"bec59744-61a3-4a54-d747-51418509dac9"},"source":["pip install face_recognition"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting face_recognition\n","  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Collecting face-recognition-models>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n","\u001b[K     |████████████████████████████████| 100.2MB 30kB/s \n","\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=cc5b4ec4cc339bfc64e12fae798778fe24b85f6ffc1a98ac80f94bca6482fa8a\n","  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UppW8ME0Jfrk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620889004438,"user_tz":-330,"elapsed":4397,"user":{"displayName":"Unnikrishnan C S","photoUrl":"","userId":"18301413610349739582"}},"outputId":"a29d6588-84f9-4dd1-9079-a77a6cd13541"},"source":["pip install imutils"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wHJOl48rt1RK","executionInfo":{"status":"ok","timestamp":1620889318309,"user_tz":-330,"elapsed":1225,"user":{"displayName":"Unnikrishnan C S","photoUrl":"","userId":"18301413610349739582"}}},"source":["# import the necessary packages\n","from imutils import paths\n","import argparse\n","import pickle\n","import cv2\n","import os\n","from google.colab import drive\n","import face_recognition #needs GPU"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"F77N4EwCt8Xq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620888460039,"user_tz":-330,"elapsed":34204,"user":{"displayName":"Unnikrishnan C S","photoUrl":"","userId":"18301413610349739582"}},"outputId":"d1fb51cc-b5c6-45db-9714-1b41e2a94f67"},"source":["drive.mount(\"/content/gdrive\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7YRloe7duF4N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620888464513,"user_tz":-330,"elapsed":1108,"user":{"displayName":"Unnikrishnan C S","photoUrl":"","userId":"18301413610349739582"}},"outputId":"2c683567-688e-47d8-e1af-00521678667d"},"source":["% cd /content/gdrive/My Drive/FaceRecog_AltMethod"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/FaceRecog_AltMethod\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"36pNa2yKJ279"},"source":["#Create image dataset...https://pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fv4EQm2bLqz2"},"source":["# Encoding the faces using OpenCV and deep learning\n","(Refer encode_faces.py)\n","To run , type below command\n","python encode_faces.py --dataset dataset --encodings encodings.pickle\n","ls -lh encodings*"]},{"cell_type":"code","metadata":{"id":"0dBSMGSrNvCx"},"source":["# construct the argument parser and parse the arguments\n","'''\n","ap = argparse.ArgumentParser()\n","\n","ap.add_argument(\"-i\", \"--dataset\", required=True,\n","\thelp=\"path to input directory of faces + images\")\n","\n","ap.add_argument(\"-e\", \"--encodings\", required=True,\n","\thelp=\"path to serialized db of facial encodings\")\n","\n","ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"cnn\",\n","\thelp=\"face detection model to use: either `hog` or `cnn`\")\n","\n","args = vars(ap.parse_args())\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Emzbof3gOniH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620889376920,"user_tz":-330,"elapsed":1453,"user":{"displayName":"Unnikrishnan C S","photoUrl":"","userId":"18301413610349739582"}},"outputId":"86ff2d24-fb25-4540-d01c-5e1663b10f3e"},"source":["# grab the paths to the input images in our dataset\n","print(\"[INFO] quantifying faces...Generating face embeddings\")\n","#imagePaths = list(paths.list_images(args[\"dataset\"]))\n","imagePaths = list(paths.list_images(\"dataset_small\"))\n","print(\"imagePaths\")\n","for (i,pth) in enumerate(imagePaths):  \n","  print(i,pth)\n","  '''\n","  print(\"pth.split(os.path.sep)\")\n","  print(pth.split(os.path.sep))\n","  print(\"pth.split(os.path.sep)[-2]\")\n","  name = pth.split(os.path.sep)[-2]\n","  print(\"name\")\n","  print(name)\n","  '''\n","\n","# initialize the list of known encodings and known names\n","knownEncodings = [] #Face Encoding\n","knownNames = [] #Correspodig Face Name"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[INFO] quantifying faces...Generating face embeddings\n","imagePaths\n","0 dataset_small/madonna/httpimgclosermagfrvarclosermagstorageimagesactupeoplebiodestarsmadonnamadonnafreFRmadonnaexactxljpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'madonna', 'httpimgclosermagfrvarclosermagstorageimagesactupeoplebiodestarsmadonnamadonnafreFRmadonnaexactxljpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","madonna\n","1 dataset_small/madonna/httpimagegaladevcmseamadonnaprivatdetektivsquaretopsquarejpgv.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'madonna', 'httpimagegaladevcmseamadonnaprivatdetektivsquaretopsquarejpgv.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","madonna\n","2 dataset_small/madonna/httpiamediaimdbcomimagesMMVBMTANDQNTAxNDVeQTJeQWpwZBbWUMDIMjQOTYVUXCRALjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'madonna', 'httpiamediaimdbcomimagesMMVBMTANDQNTAxNDVeQTJeQWpwZBbWUMDIMjQOTYVUXCRALjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","madonna\n","3 dataset_small/mindy_kaling/httpgonetworthcomwpcontentuploadsthumbsjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'mindy_kaling', 'httpgonetworthcomwpcontentuploadsthumbsjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","mindy_kaling\n","4 dataset_small/mindy_kaling/httpgraphicsnytimescomimagesmagazinekalingkalingarticleInlinejpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'mindy_kaling', 'httpgraphicsnytimescomimagesmagazinekalingkalingarticleInlinejpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","mindy_kaling\n","5 dataset_small/mindy_kaling/httpimagesnymagcomimagesdailymindykalingxjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'mindy_kaling', 'httpimagesnymagcomimagesdailymindykalingxjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","mindy_kaling\n","6 dataset_small/elton_john/httpimagesmtvcomurimgidfiledocrootvhcomsitewideflipbooksimgdailyjpgenlargefalsemattetruematteColorblackquality.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'elton_john', 'httpimagesmtvcomurimgidfiledocrootvhcomsitewideflipbooksimgdailyjpgenlargefalsemattetruematteColorblackquality.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","elton_john\n","7 dataset_small/elton_john/httpiamediaimdbcomimagesMMVBMTAxNDUMzUwOTdeQTJeQWpwZBbWUMDUOTAyNTIVUXCRALjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'elton_john', 'httpiamediaimdbcomimagesMMVBMTAxNDUMzUwOTdeQTJeQWpwZBbWUMDUOTAyNTIVUXCRALjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","elton_john\n","8 dataset_small/elton_john/httpimggalpmdstaticnetfithttpAFFwwwEgalaEfrFvarFgalFstorageFimagesFmediaFmultiuploaddufevrierFeltonjohnFfreFRFeltonjohnEjpgxqualityeltonjohnjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'elton_john', 'httpimggalpmdstaticnetfithttpAFFwwwEgalaEfrFvarFgalFstorageFimagesFmediaFmultiuploaddufevrierFeltonjohnFfreFRFeltonjohnEjpgxqualityeltonjohnjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","elton_john\n","9 dataset_small/ben_afflek/httpssmediacacheakpinimgcomxdbbdbbbececacdecdcdfjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'ben_afflek', 'httpssmediacacheakpinimgcomxdbbdbbbececacdecdcdfjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","ben_afflek\n","10 dataset_small/ben_afflek/httpcsvkmeuaeccjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'ben_afflek', 'httpcsvkmeuaeccjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","ben_afflek\n","11 dataset_small/ben_afflek/httpimagesfandangocomrImageRendererredesignstaticimgnoxportraitjpgpcpcpcimagesmasterrepositoryperformerimagespjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'ben_afflek', 'httpimagesfandangocomrImageRendererredesignstaticimgnoxportraitjpgpcpcpcimagesmasterrepositoryperformerimagespjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","ben_afflek\n","12 dataset_small/jerry_seinfeld/httpgraphicsnytimescomimagessectionmoviesfilmographyWireImagejpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'jerry_seinfeld', 'httpgraphicsnytimescomimagessectionmoviesfilmographyWireImagejpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","jerry_seinfeld\n","13 dataset_small/jerry_seinfeld/httpikinjaimgcomgawkermediaimageuploadsWmIuhdsrcedidjpgjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'jerry_seinfeld', 'httpikinjaimgcomgawkermediaimageuploadsWmIuhdsrcedidjpgjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","jerry_seinfeld\n","14 dataset_small/jerry_seinfeld/httpimagescontactmusiccomnewsimagesjerryseinfeldjpg.jpg\n","pth.split(os.path.sep)\n","['dataset_small', 'jerry_seinfeld', 'httpimagescontactmusiccomnewsimagesjerryseinfeldjpg.jpg']\n","pth.split(os.path.sep)[-2]\n","name\n","jerry_seinfeld\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s-uakyhkZyZ6"},"source":["On my Titan X GPU, processing the entire dataset took a little over a minute, but if you’re using a CPU, be prepared to wait awhile for this script complete!\n","\n","On my Macbook Pro (no GPU), encoding 218 images required 21min 20sec.\n","\n","You should expect much faster speeds if you have a GPU and compiled dlib with GPU support."]},{"cell_type":"code","metadata":{"id":"IUQQCJ7xOsAS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620891146033,"user_tz":-330,"elapsed":2288,"user":{"displayName":"Unnikrishnan C S","photoUrl":"","userId":"18301413610349739582"}},"outputId":"5af268a4-d42b-4ad7-dd1c-39898a879962"},"source":["# loop over the image paths (218 images in total)\n","for (i, imagePath) in enumerate(imagePaths):\n","\t# extract the person name from the image path\n","\tprint(\"[INFO] processing image {}/{}\".format(i + 1,\n","\t\tlen(imagePaths)))\n","\tname = imagePath.split(os.path.sep)[-2]\n","\t# load the input image and convert it from BGR (OpenCV ordering)\n","\t# to dlib ordering (RGB)\n","\timage = cv2.imread(imagePath)\n","\trgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  \n","  #localize the face and compute encodings\n","\t# detect the (x, y)-coordinates of the bounding boxes corresponding to EACH FACE in the input image.\n","\t#detection_method got from command line argumen (cnn or hog). The CNN method is more accurate but slower. HOG is faster but less accurate.\n","\t#boxes = face_recognition.face_locations(rgb,model=args[\"detection_method\"])\n","\tboxes = face_recognition.face_locations(rgb,model=\"cnn\")\n","  \n","\t# compute the facial embedding for the face...i:e encoding face to a vector\n","\tencodings = face_recognition.face_encodings(rgb, boxes)\n","\n","\t# loop over the encodings...if there are multiple faces in an image...you get multiple embeddings hence the loop\n","\tfor encoding in encodings:\n","\t\t# add each encoding + name to our set of known names and\n","\t\t# encodings\n","\t\tknownEncodings.append(encoding)\n","\t\tknownNames.append(name)\n","  \n","#view the encoding (128 dimensional vector ) and name for first face\n","print(\"\\n knownNames...First face\")\n","print(knownNames[0])\n","\n","print(\"\\n knownEncodings (128 dimensional vector)...First face\")\n","print(knownEncodings[0])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[INFO] processing image 1/15\n","[INFO] processing image 2/15\n","[INFO] processing image 3/15\n","[INFO] processing image 4/15\n","[INFO] processing image 5/15\n","[INFO] processing image 6/15\n","[INFO] processing image 7/15\n","[INFO] processing image 8/15\n","[INFO] processing image 9/15\n","[INFO] processing image 10/15\n","[INFO] processing image 11/15\n","[INFO] processing image 12/15\n","[INFO] processing image 13/15\n","[INFO] processing image 14/15\n","[INFO] processing image 15/15\n","\n"," knownNames...First face\n","madonna\n","\n"," knownEncodings (128 dimensional vector)...First face\n","[-1.19428098e-01  1.08968154e-01  1.65572912e-01 -9.16376412e-02\n"," -1.55312151e-01 -7.69698769e-02  4.13575768e-03 -1.20405078e-01\n","  1.78982139e-01 -9.95569676e-02  8.31004828e-02 -9.77365151e-02\n"," -3.26997370e-01  5.77686056e-02 -5.23638725e-02  1.16797946e-01\n"," -1.41080186e-01 -2.53044665e-01 -1.36826664e-01 -1.37425765e-01\n","  4.31917161e-02  4.67423871e-02  2.77015753e-03  8.12028497e-02\n"," -1.77818835e-01 -2.64143735e-01 -9.11574811e-02 -2.37925164e-03\n","  4.90039214e-03 -1.56245187e-01  1.17589228e-01  1.34113699e-01\n"," -1.96958154e-01  2.22429745e-02  1.69958249e-02  9.50819403e-02\n","  5.20305037e-02 -1.95531398e-01  2.20006630e-01 -4.23836224e-02\n"," -2.80786604e-01 -8.23620558e-02  1.65351838e-01  2.94506937e-01\n","  2.74727404e-01  1.02462694e-02 -3.64016071e-02 -5.62384650e-02\n","  2.23941341e-01 -3.64484489e-01  3.79383117e-02  1.70491338e-01\n","  5.22965491e-02  7.22377747e-02  9.09035727e-02 -2.69315332e-01\n","  7.18003958e-02  1.17007479e-01 -2.06037611e-01  3.08412444e-02\n","  8.91593099e-02 -2.16430873e-01  1.29394978e-02 -1.07744008e-01\n","  2.37943515e-01  1.02071762e-01 -1.17564097e-01 -1.66234434e-01\n","  2.25037098e-01 -2.56559968e-01 -3.73682231e-02  1.20800570e-01\n"," -9.47112143e-02 -6.82658926e-02 -2.90026724e-01 -4.42886651e-02\n","  4.54509616e-01  1.14538431e-01 -1.42369345e-01  1.06485628e-01\n"," -1.04280241e-01  2.35253908e-02 -4.57808599e-02  1.43992767e-01\n"," -1.04381911e-01 -3.98188829e-04 -1.45482063e-01  3.06285918e-04\n","  3.27397645e-01  5.47170639e-05 -1.24272853e-02  2.73692042e-01\n","  5.19929901e-02 -4.82751578e-02  5.20010814e-02 -5.10920584e-03\n"," -1.67601347e-01 -2.97422707e-02 -1.25670537e-01  3.84336188e-02\n"," -5.34965694e-02 -8.94716159e-02 -2.54308134e-02  1.07055441e-01\n"," -2.35469952e-01  2.05974147e-01 -7.52740912e-03 -2.04188451e-02\n"," -9.50363725e-02 -7.54406303e-02 -6.20703176e-02  3.93404067e-03\n","  1.84439391e-01 -3.42000127e-01  1.38278753e-01  1.26762271e-01\n","  4.42061499e-02  1.93907842e-01  2.82898694e-02  1.55315459e-01\n","  3.94929498e-02 -9.28026438e-03 -7.75068700e-02 -9.22953635e-02\n","  5.95582873e-02 -1.04848839e-01  3.72689143e-02  1.13673434e-01]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SanidkFNOsoH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620891250200,"user_tz":-330,"elapsed":1193,"user":{"displayName":"Unnikrishnan C S","photoUrl":"","userId":"18301413610349739582"}},"outputId":"add529ea-b8c1-4ef2-ecdb-860d540e45e3"},"source":["# dump the facial encodings + names to disk\n","# This file contains the 128-d face embeddings for each face in our dataset\n","print(\"[INFO] serializing encodings...\")\n","data = {\"encodings\": knownEncodings, \"names\": knownNames}\n","#f = open(args[\"encodings\"], \"wb\") #args[\"encodings\"] passed from command line...Filename where the encoding to be saved\n","f = open(\"encodings.pickle\", \"wb\") \n","f.write(pickle.dumps(data))\n","f.close()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[INFO] serializing encodings...\n"],"name":"stdout"}]}]}